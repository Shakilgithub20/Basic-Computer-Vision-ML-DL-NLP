{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_Code_Nnfl.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt8_SxJDEROo"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JatwTBNEKa1Z"
      },
      "source": [
        "def sigmoid(z, derive=False):\n",
        "  if derive == True:\n",
        "    return z*(1-z)\n",
        "    \n",
        "  # sigmoid rule\n",
        "  return 1/(1+np.exp(-z))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4sh4vz7EovG",
        "outputId": "49ffda2d-ffaf-4f47-f5fd-2a4ed25363a4"
      },
      "source": [
        "# Training Set\n",
        "X = np.array( [[1, 0, 0, 0],\n",
        "               [1, 0, 0, 1],\n",
        "               [1, 0, 1, 0],\n",
        "               [1, 1, 0, 1],\n",
        "               [1, 1, 0, 0],\n",
        "               [1, 1, 1, 1]] )\n",
        "\n",
        "# Gold/Actual Label or Output\n",
        "y = np.array([[0],\n",
        "              [0],\n",
        "              [0],\n",
        "              [0],\n",
        "              [0],\n",
        "              [1]])\n",
        "\n",
        "# Initialize the wights - randomly or with zeroes\n",
        "# w = np.random.random((4, 1))\n",
        "w = np.zeros((4, 1))\n",
        "w"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlXrI8nMIQZP"
      },
      "source": [
        "# Training the ANN (perceptron)... Setting No. of Iteration (epochs)\n",
        "for iter in range(1000):\n",
        "  # Forward Propagation: to Predict output (y_hat)\n",
        "  z = np.dot(X, w)\n",
        "  y_hat = sigmoid(z)\n",
        "  # print(y_hat)\n",
        "\n",
        "  # simple 'cost' calculation\n",
        "  # cost = pow((y - y_hat), 2) * 0.5    # M.S.E = Mean Squared Error\n",
        "  # cost = abs(y - y_hat) * 0.5\n",
        "  cost = y - y_hat\n",
        "\n",
        "  # Back-propagtion (future studies)\n",
        "  dy_hat = sigmoid(y_hat, derive=True)\n",
        "  delta_w = cost * dy_hat\n",
        "\n",
        "  # update weights\n",
        "  w += np.dot(X.T, delta_w)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdQlAZHLOY94",
        "outputId": "76781554-beb9-47d7-c87f-a12f8b56f8af"
      },
      "source": [
        "print(\"\\n Output after Training ...\")\n",
        "print(y_hat)\n",
        "\n",
        "print(\"\\n Weights:\")\n",
        "print(w)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Output after Training ...\n",
            "[[1.85293178e-04]\n",
            " [3.24981421e-03]\n",
            " [4.84029659e-02]\n",
            " [5.42477690e-02]\n",
            " [3.24981421e-03]\n",
            " [9.40273030e-01]]\n",
            "\n",
            " Weights:\n",
            "[[-8.5950654 ]\n",
            " [ 2.86804413]\n",
            " [ 5.61593016]\n",
            " [ 2.86804413]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO8nZja-P1xt",
        "outputId": "59bbd44f-fcca-40aa-958f-9f3e4e4eacba"
      },
      "source": [
        "# Test Set\n",
        "T = np.array([[1, 0, 1, 1],\n",
        "              [1, 1, 1, 0]])\n",
        "\n",
        "# Final Predictions on the Test Set\n",
        "y_hat = sigmoid(np.dot(T, w))\n",
        "\n",
        "print(\"\\nTest Predictions...\")\n",
        "print(y_hat)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Predictions...\n",
            "[[0.47225575]\n",
            " [0.47225575]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n7iBL9Ryp1H"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdW8fzpanZTr"
      },
      "source": [
        "sentence_bn = ['‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶Ü‡¶ú ‡¶≤‡ßç‡¶Ø‡¶æ‡¶¨ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶è ‡¶®‡¶ø‡¶â‡¶∞‡¶æ‡¶≤ ‡¶®‡ßá‡¶ü‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶ï ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨', '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡ßã‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡¶ø‡¶Ç ‡¶Ö‡¶®‡ßá‡¶ï ‡¶≠‡¶æ‡¶≤‡ßã ‡¶≤‡¶æ‡¶ó‡ßá', '‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶∏‡¶¨‡¶æ‡¶á ‡¶è‡¶á ‡¶ï‡ßã‡¶∞‡ßç‡¶∏‡ßá ‡¶≠‡¶æ‡¶≤‡ßã ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï ‡¶™‡ßá‡¶§‡ßá ‡¶ö‡¶æ‡¶á']\n",
        "sentence_en = ['We do not know how to implement a neural network', 'We don\\'t like programking at all', 'We are in great doubt about our marks in this course']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3yP1_CeosWd",
        "outputId": "3a27d49c-7928-4b0b-f4ff-bf312c50d3cf"
      },
      "source": [
        "import nltk\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diXsU2vrpCug",
        "outputId": "e83e672c-2474-4415-adfd-175fd1a12325"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vec = CountVectorizer()\n",
        "# vec.fit(sentence_bn)\n",
        "model = vec.fit_transform(sentence_en)\n",
        "\n",
        "vec.vocabulary_\n",
        "vocab_list = vec.get_feature_names()\n",
        "print(vocab_list)\n",
        "# print(model.toarray())\n",
        "count_list = model.toarray().sum(axis=0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['about', 'all', 'are', 'at', 'course', 'do', 'don', 'doubt', 'great', 'how', 'implement', 'in', 'know', 'like', 'marks', 'network', 'neural', 'not', 'our', 'programking', 'this', 'to', 'we']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kLWD_cYvWYk",
        "outputId": "23e146b4-3635-4ba8-9b75-ba08156a7abb"
      },
      "source": [
        "print(dict(zip(vocab_list,count_list)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'about': 1, 'all': 1, 'are': 1, 'at': 1, 'course': 1, 'do': 1, 'don': 1, 'doubt': 1, 'great': 1, 'how': 1, 'implement': 1, 'in': 2, 'know': 1, 'like': 1, 'marks': 1, 'network': 1, 'neural': 1, 'not': 1, 'our': 1, 'programking': 1, 'this': 1, 'to': 1, 'we': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPLjz4YCvu6Z",
        "outputId": "0bf347de-dfe4-4cea-ca43-cb68ce717301"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "vec_new = CountVectorizer(encoding='utf-8', tokenizer=word_tokenize)\n",
        "vec_new.fit(sentence_bn)\n",
        "\n",
        "vocab_list_bn = vec_new.get_feature_names()\n",
        "print(vocab_list_bn)\n",
        "print(vec_new.vocabulary_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['‡¶Ö‡¶®‡ßá‡¶ï', '‡¶Ü‡¶ú', '‡¶Ü‡¶Æ‡¶∞‡¶æ', '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞', '‡¶è', '‡¶è‡¶á', '‡¶ï‡¶∞‡¶¨', '‡¶ï‡ßã‡¶∞‡ßç‡¶∏‡ßá', '‡¶ï‡ßç‡¶≤‡¶æ‡¶∏', '‡¶ö‡¶æ‡¶á', '‡¶®‡¶ø‡¶â‡¶∞‡¶æ‡¶≤', '‡¶®‡ßá‡¶ü‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶ï', '‡¶™‡ßá‡¶§‡ßá', '‡¶™‡ßç‡¶∞‡ßã‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡¶ø‡¶Ç', '‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ó', '‡¶≠‡¶æ‡¶≤‡ßã', '‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï', '‡¶≤‡¶æ‡¶ó‡ßá', '‡¶≤‡ßç‡¶Ø‡¶æ‡¶¨', '‡¶∏‡¶¨‡¶æ‡¶á']\n",
            "{'‡¶Ü‡¶Æ‡¶∞‡¶æ': 2, '‡¶Ü‡¶ú': 1, '‡¶≤‡ßç‡¶Ø‡¶æ‡¶¨': 18, '‡¶ï‡ßç‡¶≤‡¶æ‡¶∏': 8, '‡¶è': 4, '‡¶®‡¶ø‡¶â‡¶∞‡¶æ‡¶≤': 10, '‡¶®‡ßá‡¶ü‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶ï': 11, '‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ó': 14, '‡¶ï‡¶∞‡¶¨': 6, '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞': 3, '‡¶™‡ßç‡¶∞‡ßã‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡¶ø‡¶Ç': 13, '‡¶Ö‡¶®‡ßá‡¶ï': 0, '‡¶≠‡¶æ‡¶≤‡ßã': 15, '‡¶≤‡¶æ‡¶ó‡ßá': 17, '‡¶∏‡¶¨‡¶æ‡¶á': 19, '‡¶è‡¶á': 5, '‡¶ï‡ßã‡¶∞‡ßç‡¶∏‡ßá': 7, '‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï': 16, '‡¶™‡ßá‡¶§‡ßá': 12, '‡¶ö‡¶æ‡¶á': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO98z51Hxeu1",
        "outputId": "5aac2453-288b-4660-a639-14d5d82e2fbd"
      },
      "source": [
        "# Tokenization\n",
        "\n",
        "tokenized_bn = []\n",
        "\n",
        "new_sentence = sentence_bn + ['‡¶è‡¶á‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶®‡¶§‡ßÅ‡¶® ‡¶Ü‡¶∞‡ßã ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø ‡¶∞‡¶æ‡¶ñ‡¶≤‡¶æ‡¶Æ']\n",
        "\n",
        "for sent in new_sentence:\n",
        "  tokenized_sent = word_tokenize(sent)\n",
        "  # print(tokenized_sent)\n",
        "  tokenized_bn.append(tokenized_sent)\n",
        "\n",
        "print(tokenized_bn)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['‡¶Ü‡¶Æ‡¶∞‡¶æ', '‡¶Ü‡¶ú', '‡¶≤‡ßç‡¶Ø‡¶æ‡¶¨', '‡¶ï‡ßç‡¶≤‡¶æ‡¶∏', '‡¶è', '‡¶®‡¶ø‡¶â‡¶∞‡¶æ‡¶≤', '‡¶®‡ßá‡¶ü‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶ï', '‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ó', '‡¶ï‡¶∞‡¶¨'], ['‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞', '‡¶™‡ßç‡¶∞‡ßã‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡¶ø‡¶Ç', '‡¶Ö‡¶®‡ßá‡¶ï', '‡¶≠‡¶æ‡¶≤‡ßã', '‡¶≤‡¶æ‡¶ó‡ßá'], ['‡¶Ü‡¶Æ‡¶∞‡¶æ', '‡¶∏‡¶¨‡¶æ‡¶á', '‡¶è‡¶á', '‡¶ï‡ßã‡¶∞‡ßç‡¶∏‡ßá', '‡¶≠‡¶æ‡¶≤‡ßã', '‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï', '‡¶™‡ßá‡¶§‡ßá', '‡¶ö‡¶æ‡¶á'], ['‡¶è‡¶á‡¶ñ‡¶æ‡¶®‡ßá', '‡¶Ü‡¶Æ‡¶∞‡¶æ', '‡¶®‡¶§‡ßÅ‡¶®', '‡¶Ü‡¶∞‡ßã', '‡¶è‡¶ï‡¶ü‡¶ø', '‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø', '‡¶∞‡¶æ‡¶ñ‡¶≤‡¶æ‡¶Æ']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fgLAzMixBTW"
      },
      "source": [
        "# Manually Implement the Number of Occurences of each words in the sentence_bn dataset - C.W"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXBzX-7-1J9a",
        "outputId": "b62979ce-6d11-48b3-b134-7249fa62132f"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "std_names = ['‡¶ú‡¶ø‡ßü‡¶æ‡¶¶', '‡¶®‡ßü‡¶®', '‡¶ï‡¶ø‡¶∂‡ßã‡¶∞', '‡¶¨‡¶ø‡¶≤‡¶æ‡¶∏', '‡¶á‡¶Æ‡¶§‡¶ø‡ßü‡¶æ‡¶ú‡ßÅ‡¶≤', '‡¶Æ‡¶®‡¶ø‡¶∞‡ßÅ‡¶≤' , '‡¶®‡ßü‡¶®']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "name_labels = encoder.fit_transform(std_names)\n",
        "\n",
        "# dense representation\n",
        "print(name_labels)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 1 4 0 5 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsBp-m1o1Ju0",
        "outputId": "0fb8d78d-1dc7-48d5-8d7f-5ad0b3df8949"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "name_labels = name_labels.reshape((7, 1))\n",
        "\n",
        "sparse_rep = encoder.fit_transform(name_labels).toarray()\n",
        "print(sparse_rep)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ErNQ4BHy-0-"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4pk2muJSvYz",
        "outputId": "4e4487e8-5136-4b43-ef89-b628389ec368"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbHHVXbKXc4z"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(1000, 5)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpWAb8YXX44N",
        "outputId": "6417ca7b-3326-4b32-fd45-5713cf1a2546"
      },
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04963868, -0.01968982,  0.01111265, -0.02539588,  0.0450342 ],\n",
              "       [-0.02905295, -0.03385232,  0.02321938, -0.0279748 , -0.00261045],\n",
              "       [ 0.02179753, -0.0216635 ,  0.00325959,  0.03234151,  0.01134565]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEzJFRzbYZ71",
        "outputId": "404befad-2228-48b5-ba7a-ae89b74b7a58"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "sentence = ['‡¶è‡¶á ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡ßá ‡¶ú‡¶æ‡¶®‡¶æ ‡¶ó‡ßá‡¶≤‡ßã ‡¶¶‡ßá‡¶∂ ‡¶è‡¶∞ ‡¶ï‡¶∞‡ßã‡¶®‡¶æ ‡¶™‡¶∞‡¶ø‡¶∏‡ßç‡¶•‡¶ø‡¶§‡¶ø‡¶∞ ‡¶â‡¶®‡ßç‡¶®‡¶§‡¶ø ‡¶π‡ßü‡ßá‡¶õ‡ßá', \n",
        "            '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶æ‡¶ú‡ßá ‡¶Æ‡ßÅ‡¶ñ‡ßã‡¶∂‡¶ß‡¶æ‡¶∞‡ßÄ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶Ö‡¶≠‡¶æ‡¶¨ ‡¶®‡¶æ‡¶á', \n",
        "            '‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡¶ø‡¶® ‡¶¶‡¶ø‡¶® ‡¶¨‡ßã‡¶ï‡¶æ‡¶∞ ‡¶∞‡¶æ‡¶ú‡ßç‡¶Ø‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶∏‡¶ø‡¶§ ‡¶π‡¶ö‡ßç‡¶õ‡¶ø']\n",
        "\n",
        "tokenizer.fit_on_texts(sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences(sentence)\n",
        "\n",
        "sequence"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
              " [14, 15, 16, 17, 18, 19],\n",
              " [20, 1, 1, 21, 22, 23, 24]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G10BENsTafAa",
        "outputId": "acc22cba-dbde-468f-9870-2f39f043acc4"
      },
      "source": [
        "result = embedding_layer(tf.constant(sequence[0]))\n",
        "result.numpy()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02905295, -0.03385232,  0.02321938, -0.0279748 , -0.00261045],\n",
              "       [ 0.02179753, -0.0216635 ,  0.00325959,  0.03234151,  0.01134565],\n",
              "       [ 0.03221888,  0.04403212,  0.04695613,  0.04018353, -0.00687975],\n",
              "       [ 0.04763016,  0.0004434 , -0.02749204,  0.02341368, -0.03677921],\n",
              "       [-0.02460402, -0.03339466,  0.00023228,  0.02098242,  0.00367998],\n",
              "       [ 0.02211041, -0.02584176, -0.0296883 ,  0.04999756, -0.03297983],\n",
              "       [ 0.04393085,  0.0045329 ,  0.01364804, -0.03426585, -0.02552226],\n",
              "       [-0.00521391,  0.0494909 ,  0.00989445,  0.00033556, -0.02501909],\n",
              "       [-0.01824832, -0.04194999, -0.01358656, -0.04907768,  0.02796395],\n",
              "       [-0.000151  ,  0.02046824,  0.03847941,  0.02208743,  0.01204553],\n",
              "       [ 0.02858442,  0.00445946, -0.03480124,  0.0341277 , -0.00523623],\n",
              "       [-0.01782662,  0.01902096,  0.03889645,  0.00678461,  0.00323581]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF357AqLhRHO"
      },
      "source": [
        "from numpy import array\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dense, LSTM, Bidirectional"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cICBB2hTh5r7"
      },
      "source": [
        "# Real Life Example of Classification\n",
        "\n",
        "train_ex = ['‡¶™‡¶£‡ßç‡¶Ø ‡ßß‡ß¶‡ß¶% ‡¶Ö‡¶∞‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶á‡¶ú ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶Ü‡¶∏‡¶õ‡ßá ‡¶ì‡¶ü‡¶æ ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶®‡¶æ‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡ß™‡ß®',\n",
        "             '‡¶ú‡ßÅ‡¶§‡¶æ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡ßá‡¶∞ ‡¶õ‡¶ø‡¶≤ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶≠‡¶æ‡¶∞‡ßÄ ‡¶Æ‡¶®‡ßá ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶ú‡ßÅ‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶∂‡¶ï‡ßç‡¶§‡•§ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü‡¶ü‡¶ø ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá ‡¶Ø‡¶æ ‡¶ö‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶§‡¶æ‡¶á ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø  ‡¶ì‡¶≠‡¶æ‡¶∞‡¶Ö‡¶≤ ‡¶≠‡¶æ‡¶≤‡ßã',\n",
        "             '‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶ø‡¶∏‡ßç‡¶Æ‡¶ø‡¶§, ‡¶†‡¶ø‡¶ï ‡¶Ø‡ßá‡¶Æ‡¶®‡¶ü‡¶ø ‡¶ö‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶§‡ßá‡¶Æ‡¶®‡¶ü‡¶ø ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡•§‡•§ ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡•§',\n",
        "             '‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£...‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡•§ ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡•§',\n",
        "             '‡¶¨‡ßá‡¶∂‡¶ø ‡¶¨‡¶≤‡¶¨‡¶®‡¶æ ‡¶è‡¶ï‡¶ï‡¶•‡¶æ‡ßü ‡¶è‡¶ï‡¶∂‡¶§‡ßá ‡¶è‡¶ï‡¶∂‡•§ ‡¶¶‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ñ‡ßÅ‡¶¨‡¶á‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü, ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶≤‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø‡¶ï‡ßá‡•§',\n",
        "             '‡¶ñ‡ßÅ‡¶¨ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶¨‡¶≤‡¶æ ‡¶ö‡¶≤‡ßá ‡¶®‡¶æ‡•§ ‡¶ö‡¶æ‡¶á‡¶≤‡¶æ‡¶Æ ‡ß™‡ßß ‡¶Ü‡¶∞ ‡¶¶‡¶ø‡¶≤‡ßã ‡ß™‡ß¶‡•§‡•§‡¶ì‡¶®‡¶æ‡¶∞‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞‡¶æ‡¶á ‡¶≠‡¶æ‡¶≤‡ßã ‡¶∞‡¶ø‡¶≠‡¶ø‡¶â ‡¶¶‡ßá‡ßü ‡¶ï‡¶æ‡¶∏‡ßç‡¶ü‡¶Æ‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶®‡ßç‡¶Ø‡ßá',\n",
        "             '‡¶π‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶Ö‡¶®‡ßá‡¶ï ‡¶Ü‡¶® ‡¶á‡¶ú‡¶ø ‡¶™‡¶æ ‡¶¨‡¶æ‡¶ï‡¶æ‡¶§‡ßá ‡¶™‡ßç‡¶∞‡¶¨‡ßç‡¶≤‡ßá‡¶Æ ‡¶π‡ßü',\n",
        "             '‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶è‡¶∞ ‡¶Æ‡¶§ ‡¶è‡¶á ‡¶∞‡¶ï‡¶Æ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶Ü‡¶∂‡¶æ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡ßü ‡¶®‡¶æ',\n",
        "             '‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶§‡ßã ‡¶∏‡¶¨‡¶∏‡¶Æ‡ßü‡¶á ‡¶≠‡¶æ‡¶≤‡ßã ‡¶¨‡¶æ‡¶ü ‡¶°‡ßá‡¶≤‡¶ø‡¶≠‡¶æ‡¶∞‡¶ø ‡¶¨‡¶æ‡¶ú‡ßá ‡¶õ‡¶ø‡¶≤‡ßãüò°üò°üò° ‡¶Ø‡ßá‡¶¶‡¶ø‡¶® ‡¶¶‡ßá‡ßü‡¶æ‡¶∞ ‡¶ï‡¶•‡¶æ ‡¶è‡¶∞ ‡ß® ‡¶¶‡¶ø‡¶® ‡¶™‡¶∞ ‡¶¶‡¶ø‡¶õ‡ßá...',\n",
        "             '‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶∏‡ßá‡¶≤‡¶æ‡¶∞‡•§ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶¶‡¶ø‡ßü‡¶æ ‡¶¨‡¶≤‡ßç‡¶≤‡¶æ‡¶Æ ‡¶∏‡¶æ‡¶á‡¶ú ‡¶Ø‡¶æ‡¶§‡ßá ‡¶â‡¶≤‡ßç‡¶ü‡ßã‡¶™‡¶æ‡¶≤‡ßç‡¶ü‡¶æ ‡¶®‡¶æ ‡¶Ü‡¶∏‡ßá‡•§ ‡¶ï‡ßá‡¶â ‡¶Ö‡¶∞‡¶°‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶π‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§‡•§'\n",
        "             ]\n",
        "\n",
        "# Reviews -- negative = 0 || positive = 1 (class/labels)\n",
        "train_label = array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iBFjv-kbkdLB",
        "outputId": "3f12d0cd-d1c9-4195-9c9f-d8396402cbc7"
      },
      "source": [
        "train_ex[3]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£...‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡•§ ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡•§'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWv_Zwjkjy-",
        "outputId": "5f77b1c5-ac35-439c-e145-772c95a44f18"
      },
      "source": [
        "# tokenization and converting words into sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_ex)\n",
        "dense_train_ex = tokenizer.texts_to_sequences(train_ex)\n",
        "\n",
        "dense_train_ex"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[14, 15, 16, 17, 5, 6, 18, 19, 20, 21, 22, 7, 5, 23, 24],\n",
              " [8, 25, 26, 27, 28, 29, 30, 8, 9, 31, 32, 10, 33, 34, 11, 35, 36, 37, 1],\n",
              " [38, 39, 10, 40, 11, 41, 42, 2, 3, 2, 43],\n",
              " [44, 2, 45, 46, 47, 4, 48, 49],\n",
              " [50, 51, 52, 53, 54, 55, 56, 57, 4, 2, 58, 9, 59, 60],\n",
              " [61, 62, 1, 63, 64, 7, 65, 66, 67, 68, 69, 70, 1, 71, 72, 73, 74, 75],\n",
              " [76, 77, 78, 79, 80, 81, 82, 83, 84],\n",
              " [3, 12, 85, 86, 87, 4, 88, 89, 90, 13],\n",
              " [3, 91, 92, 1, 93, 94, 95, 96, 97, 98, 99, 12, 100, 101, 102, 103],\n",
              " [104, 105, 106, 107, 108, 6, 109, 110, 13, 111, 112, 113, 114, 115, 116, 117]]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AgdiZbTnIfZ",
        "outputId": "86a54f7a-52ca-4643-f734-49eae14be1d0"
      },
      "source": [
        "# padding the training documents in order to make them equal length\n",
        "MAX_LENGTH = 16\n",
        "\n",
        "padded_train_ex = pad_sequences(dense_train_ex, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "for pd_sen in padded_train_ex:\n",
        "  print(pd_sen)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14 15 16 17  5  6 18 19 20 21 22  7  5 23 24  0]\n",
            "[27 28 29 30  8  9 31 32 10 33 34 11 35 36 37  1]\n",
            "[38 39 10 40 11 41 42  2  3  2 43  0  0  0  0  0]\n",
            "[44  2 45 46 47  4 48 49  0  0  0  0  0  0  0  0]\n",
            "[50 51 52 53 54 55 56 57  4  2 58  9 59 60  0  0]\n",
            "[ 1 63 64  7 65 66 67 68 69 70  1 71 72 73 74 75]\n",
            "[76 77 78 79 80 81 82 83 84  0  0  0  0  0  0  0]\n",
            "[ 3 12 85 86 87  4 88 89 90 13  0  0  0  0  0  0]\n",
            "[  3  91  92   1  93  94  95  96  97  98  99  12 100 101 102 103]\n",
            "[104 105 106 107 108   6 109 110  13 111 112 113 114 115 116 117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu9NqNL9n3Zb",
        "outputId": "a2761ba0-b481-4e79-a4c4-748851db0572"
      },
      "source": [
        "# Model Declaration\n",
        "VOCAB_SIZE = 118\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding Layer\n",
        "embedding_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=8, input_length=MAX_LENGTH)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "# # Flatten Layer\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(units=160, activation='relu'))\n",
        "# model.add(Dense(units=80, activation='relu'))\n",
        "# model.add(Dense(units=40, activation='relu'))\n",
        "# model.add(Dense(units=10, activation='relu'))\n",
        "\n",
        "# LSTM - for better performance\n",
        "# model.add(LSTM(units=128))\n",
        "\n",
        "# Bidirectional LSTM\n",
        "forward_layers = LSTM(units=128, return_sequences=False)\n",
        "backward_layers = LSTM(units=128, return_sequences=False, go_backwards=True)\n",
        "model.add(Bidirectional(layer=forward_layers, backward_layer=backward_layers))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 16, 8)             944       \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               140288    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 141,489\n",
            "Trainable params: 141,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InvCtAjsrxPX",
        "outputId": "9cf82246-afe8-48b8-ae96-a46ab1736b14"
      },
      "source": [
        "model.fit(padded_train_ex, train_label, epochs=10, verbose=1)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2500 - acc: 0.4000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2496 - acc: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2492 - acc: 0.7000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2487 - acc: 0.7000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2481 - acc: 0.7000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2473 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2464 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2452 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2438 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2419 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9e574a5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBAB4FT4sKO9",
        "outputId": "ae832bbf-1ea2-42a4-adcb-242c7be4cae7"
      },
      "source": [
        "# Testing\n",
        "test_ex = ['‡¶¶‡¶æ‡¶Æ‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶π‡¶≤‡ßá‡¶ì ‡¶Æ‡¶æ‡¶®‡ßá ‡¶≠‡¶æ‡¶≤‡ßã, ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú ‡¶ï‡ßá', \n",
        "           '‡¶ú‡ßÅ‡¶§‡¶æ‡¶ü‡¶ø ‡¶π‡¶æ‡¶§‡ßá ‡¶™‡ßá‡ßü‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶á ‡¶¨‡¶ø‡¶∏‡ßç‡¶Æ‡¶ø‡¶§', \n",
        "           '‡¶è‡¶ï‡¶¶‡¶Æ ‡¶¨‡¶æ‡¶ú‡ßá, ‡¶Æ‡¶®‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶π‡¶≤‡¶æ‡¶Æ üò°',\n",
        "           '‡¶è‡¶§‡ßã ‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶™‡ßç‡¶∞‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶™‡¶¨‡ßã ‡¶Ü‡¶∂‡¶æ ‡¶ï‡¶∞‡¶ø ‡¶®‡¶ø']\n",
        "\n",
        "# tokenization and converting words into sequence\n",
        "dense_test_ex = tokenizer.texts_to_sequences(test_ex)\n",
        "\n",
        "# padding the test documents\n",
        "padded_test_ex = pad_sequences(dense_test_ex, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "prediction = model.predict(padded_test_ex)\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.501005  ]\n",
            " [0.5013156 ]\n",
            " [0.50083774]\n",
            " [0.49560586]]\n"
          ]
        }
      ]
    }
  ]
}